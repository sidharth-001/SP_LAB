{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment9.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTVtaswOb2EowIPanzMD5Q"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"izElb4Rq8fMO"},"source":["#**Author:**\n","* ## **Sidharth**\n","* ### *2K18/ MC/ 114*"]},{"cell_type":"markdown","metadata":{"id":"JFUAkvzb8sIN"},"source":["#**Objective:**\n","### Demonstrate Markov Chain. WAP to implement Markov Chain\n","### 1. Gambler Ruin Problem\n","### 2. Weather Forecasting Problem"]},{"cell_type":"markdown","metadata":{"id":"mdFwnjNc-Gxj"},"source":["#**Theory:**\n","#### Modern probability theory studies chance processes for which the knowledge of previous outcomes influences predictions for future experiments. In principle, when we observe a sequence of chance experiments, all of the past outcomes could influence our predictions for the next experiment. For example, this should be the case in predicting a student’s grades on a sequence of exams in a course. But to allow this much generality would make it very difficult to prove general results.\n","\n","#### A Markov chain is a stochastic process, but it differs from a general stochastic process in that a Markov chain must be \"memory-less.\" That is, (the probability of) future actions are not dependent upon the steps that led up to the present state. This is called the Markov property. While the theory of Markov chains is important precisely because so many \"everyday\" processes satisfy the Markov property, there are many common examples of stochastic properties that do not satisfy the Markov property.\n","\n","#### We describe a Markov chain as follows: We have a set of states, S = {s1, s2,...,sr}. The process starts in one of these states and moves successively from one state to another. Each move is called a step. If the chain is currently in state si, then it moves to state sj at the next step with a probability denoted by pij , and this probability does not depend upon which states the chain was in before the current state."]},{"cell_type":"markdown","metadata":{"id":"45IYFugZ-t6h"},"source":["#**Code and Output:**"]},{"cell_type":"markdown","metadata":{"id":"FGguP0XF_nlc"},"source":["## 1. Gambler Ruin Problem\n","> #### A gambler has a fortune of ₹20 and he bets ₹1 at a time and wins ₹1 with probability 3/10. He stops playing if he loses all his fortune or doubles it. Write the transition probability matrix that he loses his fortune at the end of 30 plays."]},{"cell_type":"code","metadata":{"id":"6BK3INSS8Pk2","executionInfo":{"status":"ok","timestamp":1603016910761,"user_tz":-330,"elapsed":1816,"user":{"displayName":"Sidharth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKYBc4FiXLN_LJ2C_0bA9UD1pxIW75rn2Bfx23xA=s64","userId":"16336888073881821839"}},"outputId":"d4337a97-12a2-478e-fd7f-1847ab490f4e","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["p = 0.3\n","n = 30\n","fortune = 20\n","\n","import numpy as np\n","tm=np.zeros(shape=(int(2*fortune+1), int(2*fortune+1)))\n","print(\"Absorbing barriers are at\", 0, \"and\", 2*fortune)\n","for i in range(0, int(2*fortune+1)):\n","    for j in range(0 ,int(2*fortune+1)):\n","        if i==0 or i==int(2*fortune):\n","            tm[i][i]=1\n","        else:\n","            if i+1==j:\n","                tm[i][j]=p\n","            elif i-1==j:\n","                tm[i][j]=1-p\n","\n","b=np.linalg.matrix_power(tm, n)\n","print(\"Probability of gambler losing his fortune at the end of\", n, \"plays:\")\n","print(b[int(fortune)][0])"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Absorbing barriers are at 0 and 40\n","Probability of gambler losing his fortune at the end of 30 plays:\n","0.08067671520774745\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RjTXba4pEtBE"},"source":["## 2. Weather Forecasting Problem\n","> #### Provided with every states probability that rain occurs yesterday and today. Let it rained on both Saturday and Sunday. What is the probability that it will rain on Monday?\n","\n","> ### We have Probabilities:\n","* #### State 0: Rained today and yesterday: 0.4\n","* #### State 1: Rained today but not yesterday: 0.2\n","* #### State 2: Rained yesterday but not today: 0.3\n","* #### State 3: Didn't rain today or yesterday: 0.5"]},{"cell_type":"code","metadata":{"id":"G5-1K8aUgpNf","executionInfo":{"status":"ok","timestamp":1603016931010,"user_tz":-330,"elapsed":1142,"user":{"displayName":"Sidharth","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKYBc4FiXLN_LJ2C_0bA9UD1pxIW75rn2Bfx23xA=s64","userId":"16336888073881821839"}},"outputId":"e3bcb60e-c7ed-432f-a808-61095ba07e1c","colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["import numpy as np\n","import math\n","\n","state0 = 0.4\n","state1 = 0.2\n","state2 = 0.3\n","state3 = 0.5\n","wid = 4\n","hig = 4\n","\n","tm = [[0 for x in range(wid)] for y in range(hig)]\n","\n","tm[0][0] = state0\n","tm[0][2] = 1-state0\n","tm[1][0] = state1\n","tm[1][2] = 1-state1\n","tm[2][1] = state2\n","tm[2][3] = 1-state2\n","tm[3][1] = state3\n","tm[3][3] = 1-state3\n","\n","print(\"The transition matrix:\\n\")\n","for i in a:\n","    print(i)\n","\n","a=np.linalg.matrix_power(a, 2)\n","print(\"\\nProbability of raining tommorow with the past two days having rained:\")\n","print(a[0][0]+a[0][1])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["The transition matrix:\n","\n","[0.08933236 0.26764818 0.26783304 0.37518642]\n","[0.08927768 0.26764124 0.26749552 0.37558556]\n","[0.08921606 0.26813975 0.26764124 0.37500295]\n","[0.0893301  0.26785925 0.2682754  0.37453525]\n","\n","Probability of raining tommorow with the past two days having rained:\n","0.35714289990042936\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L6ekbpAj-yHB"},"source":["#**Result:**\n","#### Implemented Markov Chain for Gambler Ruin Problem and Weather Forecasting Problem."]},{"cell_type":"markdown","metadata":{"id":"1YjJ76me-2Im"},"source":["#**Discussion:**\n","#### Markov chains are an important concept in stochastic processes. They can be used to greatly simplify processes that satisfy the Markov property, namely that the future state of a stochastic variable is only dependent on its present state."]}]}